<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <link rel="stylesheet" href="style.css" />
    <title>Nea.chat</title>
  </head>
  <body>
    
    <button id="debug-button" onclick="toggleDebug()">Debug</button>
    <main>
    <button id="button">Press & Hold to speak</button>
    <p id="message" hidden aria-hidden="true">
      Your browser doesn't support Speech Recognition. Sorry.
    </p>
    <div id="result"></div>
    <p>
    <p></p>
    <div id="output"></div>
    <p></p>
    <small><div id="debug"><p>V 48</p></div></small>
   </main>

    <button id="mic-button" hidden>Press to speak</button>

  </body>
  <script>

      const lang = 'de-DE';
      const micButton = document.getElementById('mic-button');

      const historyKey = "history4";
      var conversation = JSON.parse(localStorage.getItem(historyKey) || "[]");

      const queryString = window.location.search;
      const urlParams = new URLSearchParams(queryString);
      const API_KEY = urlParams.get('API_KEY');

       // write a function that will take text and append it to a debug html element called debug
      function debug2(text) {
        // get the debug element
        let debug = document.getElementById('debug');
        // create a new p element
        let p = document.createElement('p');
        // set the text of the p element to the text passed to the function
        p.textContent = text;
        // append the p element to the debug element
        debug.appendChild(p);
      }

    debug2("loaded");
     window.addEventListener("DOMContentLoaded", () => {
        const button = document.getElementById("button");
        const result = document.getElementById("result");
        const output = document.getElementById("output");
        const main = document.getElementsByTagName("main")[0];
        let listening = false;
        let lastResult = "";
        const SpeechRecognition =
          window.SpeechRecognition || window.webkitSpeechRecognition;
        if (typeof SpeechRecognition !== "undefined") {
          const recognition = new SpeechRecognition();
          recognition.lang = lang;
          const stop = () => {
            debug2("stop");
            main.classList.remove("speaking");
            recognition.stop();
            button.textContent = "Press & Hold to speak";
            window.completeTranscript(lastResult);
            debug2("stopped");
          };

          const start = () => {
            debug
            main.classList.add("speaking");
            recognition.start();
            button.textContent = "Release to stop";
            result.textContent = "";
            output.textContent = "";
            debug2("started");
          };

          const debug = text => {
            // get the debug element
            let debug = document.getElementById('debug');
            // create a new p element
            let p = document.createElement('p');
            // set the text of the p element to the text passed to the function
            p.textContent = text;
            // append the p element to the debug element
            debug.appendChild(p);
          }

          const onResult = event => {
            result.innerHTML = "";
            for (const res of event.results) {
              const text = document.createTextNode(res[0].transcript);
              const p = document.createElement("p");
              if (res.isFinal) {
                p.classList.add("final");
                lastResult = res[0].transcript;
              }
              result.textContent = res[0].transcript;
            }
          };
          recognition.continuous = true;
          recognition.interimResults = true;
          recognition.addEventListener("result", onResult);
          /*  button.addEventListener("click", event => {
            listening ? stop() : start();
            listening = !listening;
          }); */
          button.addEventListener("touchstart", event => {
            debug2("touchstart");
            listening ? stop() : start();
            listening = true;
          });
          button.addEventListener("touchend", event => {
            debug2("touchend");
            listening ? stop() : start();
            listening = false;
          });
        } 
      });

      

      function completeTranscript2(transcript) {
        debug2("completeTranscript2");
      }

      async function completeTranscript(transcript) {
                debug2("completeTranscript");
                const input = document.createElement('p');
                input.textContent = transcript;
                
                let history = "";
                if (conversation.length > 0) {
                
                   history += "Our conversation so far:\n\n"
                   conversation.forEach(item => {
                    history += `I said: "${item.input}"\n\n`;
                    history += `You responded: "${item.output}"\n\n\n`;
                  });
                 
                } else {
                  console.log("conversation is empty");
                }
                history += `I say: "${transcript}"\n\n`;
                history += `You respond:`;
                
                const completedText = await completeText(history);   
                const output = document.createElement('p');
                output.textContent = completedText;
                document.getElementById('output').textContent = completedText;
                let turn = {
                    input: transcript,
                    output: completedText
                }
                conversation.push(turn);
                console.log(history);
                localStorage.setItem(historyKey, JSON.stringify(conversation));
  
                // Synthesize speech from the text
                const synth = window.speechSynthesis;
                const speakText = new SpeechSynthesisUtterance(completedText);
                // set the voice to german
                speakText.lang = lang;
                // Get a list of available voices
                const voices = await synth.getVoices();
                // Set the voice to the first available female voice
                speakText.voice = voices.find(voice => voice.gender === 'female');
                // if we are on Android, set the rate faster
                if (navigator.userAgent.indexOf("Android") !== -1)
                  speakText.rate = 1.2;
                synth.speak(speakText);
      }

      async function completeText(text) {
          debug2("completeText");
          var url = "https://api.openai.com/v1/completions";
          var bearer = 'Bearer ' + API_KEY;
          const response = await fetch(url, {
            method: 'POST',
            headers: {
              'Authorization': bearer,
              'Content-Type': 'application/json'
            },
            body: JSON.stringify({
              "prompt": text,
              "model": "text-davinci-003",
              "max_tokens": 1024
            })


          })
            .catch(error => {
              console.log('Something bad happened ' + error)
              debug2('Something bad happened ' + error);
            });
        debug2("request sent");
        data = await response.json();
        debug2("request received");
        return data['choices'][0].text;
         
      }
   
    var debug = true;
    function toggleDebug() {
        debug = !debug;
        if (debug) {
          document.getElementById("debug").style.display = "block";
        } else {
          document.getElementById("debug").style.display = "none";
        }
      }
  </script>
</html>
