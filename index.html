<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <link rel="stylesheet" href="style.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
    integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

  <title>Nea.chat</title>
</head>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
  integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>

<body>

  <main>
    <button id="button" class="noselect"><i class="fa fa-microphone fa-4x"></i></button>
    <p id="message" hidden aria-hidden="true">
      Your browser doesn't support Speech Recognition. Sorry.
    </p>
    <div id="result"></div>
    <p>
    <p></p>
    <div id="output"></div>
    <p></p>
    <small>
      <div id="debug" style="display: none;">
      </div>
      <p>V 90</p>
    </small>
  </main>
  <p></p>
  <p></p>
  <button id="debug-button" onclick="toggleDebug()">Debug</button>
  <p></p>
  <button id="history-button" onclick="toggleHistory()">Reset history</button>
  <p></p>
  <form>
    <!-- <input type="radio" id="english" name="language" value="en-EN">
    <label for="english">English</label>
    <br> -->
    <input type="radio" id="german" name="language" value="de-DE" checked>
    <label for="german">German</label>
  </form>

</body>
<script>
  const speakAudio = new Audio();
  speakAudio.autoplay = true;
  speakAudio.muted = true;
  // check if browser is mobile safari
  window["initialAudio"] = navigator.userAgent.match(/(iPod|iPhone|iPad)/) && navigator.userAgent.match(/AppleWebKit/);

  
  let lang = 'de-DE';
  const historyKey = "history4";
  var conversation = JSON.parse(localStorage.getItem(historyKey) || "[]");

  const queryString = window.location.search;
  const urlParams = new URLSearchParams(queryString);
  const API_KEY = urlParams.get('API_KEY');

  debug("loaded");
  window.addEventListener("DOMContentLoaded", () => {

    const button = document.getElementById("button");
    const result = document.getElementById("result");
    const output = document.getElementById("output");
    const main = document.getElementsByTagName("main")[0];
    let listening = false;
    let lastResult = "";
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (typeof SpeechRecognition !== "undefined") {
      const recognition = new SpeechRecognition();
      recognition.lang = lang;
      const stop = () => {
        debug("stop");
        main.classList.remove("speaking");
        recognition.stop();
        debug("stopped");
      };

      const start = () => {
        debug("start");
        if (window['initialAudio']){
          if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            // Check if the user has already granted microphone access
            navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {
              // The user has already granted microphone access
              console.log("Microphone access granted");
              // Stop the stream from being recorded (we only needed to check the permission)
              stream.getTracks().forEach(function (track) {
                track.stop();
              });
              if (window["initialAudio"]) {
              window.setTimeout((main, recognition, result, output)  => {
                main.classList.add("speaking");
                recognition.start();
                result.textContent = "";
                output.textContent = "";
                debug("started");
                window["initialAudio"] = false;
              }, 1500, main, recognition, result, output);
            } 
            }).catch(function (error) {
              // The user has not granted microphone access
              console.log("Microphone access not granted");
            });
          } else {
            console.log("getUserMedia API is not supported in this browser");
          }
        } else {
          main.classList.add("speaking");
          recognition.start();
          result.textContent = "";
          output.textContent = "";
          debug("started fast");
        }
      };

      const onResult = event => {
        result.innerHTML = "";    
          result.textContent =event.results[0][0].transcript;
          lastResult=event.results[0][0].transcript;
        
      };
      const end = event => {
        debug("end");
        //completeTranscript(lastResult);
        debug("ended");
      };
      recognition.addEventListener("end", end);
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.addEventListener("result", onResult);


      button.addEventListener("click", event => {
        debug("click");
        if (listening) { stop(); window.setTimeout(completeTranscript, 950, lastResult); } else start();
        listening = !listening;
      });
      
    }
  });

  function checkMicrophonePermission() {
    // Check if the browser supports the getUserMedia API
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      // Check if the user has already granted microphone access
      navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {
        // The user has already granted microphone access
        console.log("Microphone access granted");
        // Stop the stream from being recorded (we only needed to check the permission)
        stream.getTracks().forEach(function (track) {
          track.stop();
        });
      }).catch(function (error) {
        // The user has not granted microphone access
        console.log("Microphone access not granted");
        // Show the "enable microphone" button
        document.getElementById("enable-microphone-button").style.display = "block";
      });
    } else {
      console.log("getUserMedia API is not supported in this browser");
    }
  }

  async function completeTranscript(transcript, recognition) {
    debug("completeTranscript");
    debug("transcript: " + transcript);
    let history = "";
    if (conversation.length > 0) {

      history += "Our conversation so far:\n\n"
      conversation.forEach(item => {
        history += `I said: "${item.input}"\n\n`;
        history += `You responded: "${item.output}"\n\n\n`;
      });

    } else {
      console.log("conversation is empty");
    }
    history += `I say: "${transcript}"\n\n`;
    history += `You respond:`;
    document.getElementById('output').innerHTML = "<i class='fa fa-spinner fa-spin fa-4x'></i>";
    const completedText = await completeText(history);
    debug("completedText: " + completedText);
    document.getElementById('output').innerHTML = "";
    document.getElementById('output').textContent = completedText;
    let turn = {
      input: transcript,
      output: completedText
    }
    conversation.push(turn);
    console.log(history);
    localStorage.setItem(historyKey, JSON.stringify(conversation));
    speakRemote(completedText);

  }

  function activateAudio() {
    speakAudio.muted = false;
    // onClick of first interaction on page before I need the sounds
    // (This is a tiny MP3 file that is silent and extremely short - retrieved from https://bigsoundbank.com and then modified)
    speakAudio.src = "data:audio/mpeg;base64,SUQzBAAAAAABEVRYWFgAAAAtAAADY29tbWVudABCaWdTb3VuZEJhbmsuY29tIC8gTGFTb25vdGhlcXVlLm9yZwBURU5DAAAAHQAAA1N3aXRjaCBQbHVzIMKpIE5DSCBTb2Z0d2FyZQBUSVQyAAAABgAAAzIyMzUAVFNTRQAAAA8AAANMYXZmNTcuODMuMTAwAAAAAAAAAAAAAAD/80DEAAAAA0gAAAAATEFNRTMuMTAwVVVVVVVVVVVVVUxBTUUzLjEwMFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQsRbAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQMSkAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV";

  }
  function speakRemote(text) {
    speakAudio.muted = false;
    speakAudio.src = "https://europe-west3-gitty-339716.cloudfunctions.net/texttospeech?text=" + encodeURIComponent(text) + "&lang=" + lang;
    speakAudio.play();
  }

  async function completeText(text) {
    debug("completeText");

    var url = "https://api.openai.com/v1/completions";
    var bearer = 'Bearer ' + API_KEY;
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Authorization': bearer,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        "prompt": text,
        "model": "text-davinci-003",
        "max_tokens": 1024
      })


    })
      .catch(error => {
        console.log('Something bad happened ' + error)
        debug('Something bad happened ' + error);
      });
    debug("request sent");
    data = await response.json();
    debug("request received");
    return data['choices'][0].text;

  }

  function debug(text) {
    // get the debug element
    let debug = document.getElementById('debug');
    // create a new p element
    let p = document.createElement('p');
    // set the text of the p element to the text passed to the function
    p.textContent = text;
    // append the p element to the debug element
    debug.appendChild(p);
  }
  var debugflag = false;
  function toggleDebug() {
    debugflag = !debugflag;
    if (debugflag) {
      document.getElementById("debug").style.display = "block";
    } else {
      document.getElementById("debug").style.display = "none";
    }
  }

  function toggleHistory() {
    conversation = [];
    localStorage.setItem(historyKey, JSON.stringify(conversation));
  }

  const form = document.querySelector('form');

  form.addEventListener('change', event => {
    lang = event.target.value;
  });

</script>

</html>