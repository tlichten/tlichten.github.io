<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <link rel="stylesheet" href="chat.css" />
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css"
    integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/malihu-custom-scrollbar-plugin/3.1.5/jquery.mCustomScrollbar.min.css">
  <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/malihu-custom-scrollbar-plugin/3.1.5/jquery.mCustomScrollbar.min.js"></script>

  <title>talkalot.chat</title>
</head>

<body>
  <div class="container-fluid h-100">
    <div class="row justify-content-center h-100">
        <div class="col-md-8 col-xl-6 chat" id="main">
          <div class="card">
            <div class="card-header msg_head">
              <div class="text-center">
                <div class="user_info">
                  
                  <span><i class="fa fa-comments"></i> <strong>talkalot.chat</strong></span>
                </div>

              </div>
              <span id="action_menu_btn"><i class="fas fa-ellipsis-v"></i></span>
              <div class="action_menu">
                <ul>
                  <li onclick="toggleHistory();$('.action_menu').toggle();"><i class="fas fa-trash"></i> Clear conversation</li>
                  <li onclick="toggleDebug();$('.action_menu').toggle();"><i class="fas fa-code"></i> View debug</li>
                  <li><i class="fas fa-language"></i> Change language</li>
                  <li><i class="fas fa-info-circle"></i> Privacy/Terms</li>
                </ul>
              </div>
            </div>
            <div class="card-body msg_card_body" id="messages">
            </div>
            <div class="card-footer">
              <div class="input-group">
                <div class="input-group-append">
                  <span class="input-group-text attach_btn"></span>
                </div>
                <span name="" class="form-control type_msg" id="result">Tap microphone to talk</span>
                <div class="input-group-append">
                  <span class="input-group-text send_btn" id="button"><i class="fas fa-microphone fa-3x"></i></span>
                </div>
              </div>
            </div>
          </div>
        </div>
    </div>
  </div>

  <p id="message" hidden aria-hidden="true">
    Your browser doesn't support Speech Recognition. Sorry.
  </p>
  <div id="debug" hidden aria-hidden="true"></div>

</body>
<script>
  const speakAudio = new Audio();
  speakAudio.autoplay = true;
  speakAudio.muted = true;
  // check if browser is mobile safari
  window["initialAudio"] = navigator.userAgent.match(/(iPod|iPhone|iPad)/) && navigator.userAgent.match(/AppleWebKit/);


  let lang = 'de-DE';
  const historyKey = "history4";
  var conversation = JSON.parse(localStorage.getItem(historyKey) || "[]");

  const queryString = window.location.search;
  const urlParams = new URLSearchParams(queryString);
  const API_KEY = urlParams.get('API_KEY');

  debug("loaded");
  window.addEventListener("DOMContentLoaded", () => {

    const button = document.getElementById("button");
    const result = document.getElementById("result");
    const main = document.getElementById("main");
    let listening = false;
    let lastResult = "";

    loadMessagesfromConversation(conversation);


    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (typeof SpeechRecognition !== "undefined") {
      const recognition = new SpeechRecognition();
      recognition.lang = lang;
      const stop = () => {
        debug("stop");
        main.classList.remove("speaking");
        recognition.stop();
        debug("stopped");
      };

      const start = () => {
        debug("start");
        if (window['initialAudio']) {
          if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
            // Check if the user has already granted microphone access
            navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {
              // The user has already granted microphone access
              console.log("Microphone access granted");
              // Stop the stream from being recorded (we only needed to check the permission)
              stream.getTracks().forEach(function (track) {
                track.stop();
              });
              if (window["initialAudio"]) {
                window.setTimeout((main, recognition, result) => {
                  main.classList.add("speaking");
                  recognition.start();
                  result.textContent = "";
                  debug("started");
                  window["initialAudio"] = false;
                }, 1500, main, recognition, result);
              }
            }).catch(function (error) {
              // The user has not granted microphone access
              console.log("Microphone access not granted");
            });
          } else {
            console.log("getUserMedia API is not supported in this browser");
          }
        } else {
          main.classList.add("speaking");
          recognition.start();
          result.textContent = "";
          debug("started fast");
        }
      };

      const onResult = event => {
        result.innerHTML = "";
        for (const res of event.results) {
          lastResult = res[0].transcript;
          result.textContent = res[0].transcript;
        }
      };
      const end = event => {
        debug("end");
        appendMessage(lastResult);
        if (navigator.userAgent.match(/Android/i)) {
          window.setTimeout(completeTranscript, 950, lastResult);
          stop();
          listening = false;
        }
        result.textContent = "";
        debug("ended");
      };
      recognition.addEventListener("end", end);
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.addEventListener("result", onResult);

      button.addEventListener("click", event => {
        debug("click");
        if (navigator.userAgent.match(/Android/i)) {
          if (!listening) {  start(); listening = true}
        } else {   
          if (listening) { stop(); window.setTimeout(completeTranscript, 950, lastResult); } else start();
          listening = !listening;
        }
      });

    }
  });

  function checkMicrophonePermission() {
    // Check if the browser supports the getUserMedia API
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      // Check if the user has already granted microphone access
      navigator.mediaDevices.getUserMedia({ audio: true }).then(function (stream) {
        // The user has already granted microphone access
        console.log("Microphone access granted");
        // Stop the stream from being recorded (we only needed to check the permission)
        stream.getTracks().forEach(function (track) {
          track.stop();
        });
      }).catch(function (error) {
        // The user has not granted microphone access
        console.log("Microphone access not granted");
        // Show the "enable microphone" button
        document.getElementById("enable-microphone-button").style.display = "block";
      });
    } else {
      console.log("getUserMedia API is not supported in this browser");
    }
  }

  // loadMessagesfromConversation(conversation);
  function loadMessagesfromConversation(conversation) {
    conversation.forEach((item) => {
      const sendMessage = item.input;
      const receivedMessage = item.output;
      appendMessage(sendMessage, true, false);
      appendMessage(receivedMessage, false, false);
    });
    scrollToBottom("messages");
  }
  const scrollSmoothlyToBottom = (id) => {
   const element = $(`#${id}`);
   element.animate({
      scrollTop: element.prop("scrollHeight")
   }, 500);
  }

  const scrollToBottom = (id) => {
    const element = document.getElementById(id);
    element.scrollTop = element.scrollHeight;
  }
  function appendMessage(text, send=true, scroll=true)
  { 
    if($('.ticontainer').length <= 0){
      $("#messages").append(`<div class="d-flex justify-content-${send ? "end" : "start"} mb-4"><div class="msg_cotainer${send ? "_send" : ""}">${text}<span class="msg_time_send">8:55 AM, Today</span></div>`);
    } else {
      $('.ticontainer').replaceWith(`${text}`);
    }
    if(scroll)
      scrollSmoothlyToBottom("messages");
  }
  async function completeTranscript(transcript, recognition) {
    debug("completeTranscript");
    debug("transcript: " + transcript);
    let history = "";
    if (conversation.length > 0) {

      history += "Our conversation so far:\n\n"
      conversation.forEach(item => {
        history += `I said: "${item.input}"\n\n`;
        history += `You responded: "${item.output}"\n\n\n`;
      });

    } else {
      console.log("conversation is empty");
    }
    history += `I say: "${transcript}"\n\n`;
    history += `You respond:`;
    appendMessage('<div class="ticontainer"><div class="tiblock"> <div class="tidot"></div> <div class="tidot"></div> <div class="tidot"></div></div></div>', false);
    const cardBody = document.querySelector('.card-body');
    cardBody.scrollTop = cardBody.scrollHeight;
    let completedText = await completeText(history);
    completedText = completedText.replace(/"/g, "");
    debug("completedText: " + completedText);
    appendMessage(completedText, false);
    let turn = {
      input: transcript,
      output: completedText
    }
    conversation.push(turn);
    console.log(history);
    localStorage.setItem(historyKey, JSON.stringify(conversation));
    speakRemote(completedText);

  }

  function activateAudio() {
    speakAudio.muted = false;
    // onClick of first interaction on page before I need the sounds
    // (This is a tiny MP3 file that is silent and extremely short - retrieved from https://bigsoundbank.com and then modified)
    speakAudio.src = "data:audio/mpeg;base64,SUQzBAAAAAABEVRYWFgAAAAtAAADY29tbWVudABCaWdTb3VuZEJhbmsuY29tIC8gTGFTb25vdGhlcXVlLm9yZwBURU5DAAAAHQAAA1N3aXRjaCBQbHVzIMKpIE5DSCBTb2Z0d2FyZQBUSVQyAAAABgAAAzIyMzUAVFNTRQAAAA8AAANMYXZmNTcuODMuMTAwAAAAAAAAAAAAAAD/80DEAAAAA0gAAAAATEFNRTMuMTAwVVVVVVVVVVVVVUxBTUUzLjEwMFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQsRbAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQMSkAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV";

  }
  function speakRemote(text) {
    speakAudio.muted = false;
    speakAudio.src = "https://europe-west3-gitty-339716.cloudfunctions.net/texttospeech?text=" + encodeURIComponent(text) + "&lang=" + lang;
    speakAudio.play();
  }

  async function completeText(text) {
    debug("completeText");

    var url = "https://api.openai.com/v1/completions";
    var bearer = 'Bearer ' + API_KEY;
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Authorization': bearer,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        "prompt": text,
        "model": "text-davinci-003",
        "max_tokens": 1024
      })


    })
      .catch(error => {
        console.log('Something bad happened ' + error)
        debug('Something bad happened ' + error);
      });
    debug("request sent");
    data = await response.json();
    debug("request received");
    return data['choices'][0].text;

  }

  function debug(text) {
    // get the debug element
    let debug = document.getElementById('debug');
    // create a new p element
    let p = document.createElement('p');
    // set the text of the p element to the text passed to the function
    p.textContent = text;
    // append the p element to the debug element
    debug.appendChild(p);
  }
  var debugflag = false;
  function toggleDebug() {
    debugflag = !debugflag;
    if (debugflag) {
      document.getElementById("debug").style.display = "block";
    } else {
      document.getElementById("debug").style.display = "none";
    }
  }

  function toggleHistory() {
    conversation = [];
    localStorage.setItem(historyKey, JSON.stringify(conversation));
    $("#messages").empty();
  }


  $(document).ready(function(){
    $('#action_menu_btn').click(function(){
      $('.action_menu').toggle();
    });
	});

</script>

</html>