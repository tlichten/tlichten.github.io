<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <link rel="stylesheet" href="style.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <title>Nea.chat</title>
</head>

<body>

  <main>
    <button id="button"><i class="fa fa-microphone fa-4x"></i></button>
    <p id="message" hidden aria-hidden="true">
      Your browser doesn't support Speech Recognition. Sorry.
    </p>
    <div id="result"></div>
    <p>
    <p></p>
    <div id="output"></div>
    <p></p>
    <small>
      <div id="debug" style="display: none;">
      </div>
      <p>V 67</p>
    </small>
  </main>
  <p></p>
  <p></p>
  <button id="debug-button" onclick="toggleDebug()">Debug</button>
  <p></p>
  <button id="history-button" onclick="toggleHistory()">Reset history</button>
  <p></p>
  <form>
    <input type="radio" id="english" name="language" value="en-EN">
    <label for="english">English</label>
    <br>
    <input type="radio" id="german" name="language" value="de-DE" checked>
    <label for="german">German</label>
  </form>

</body>
<script>
  const speakAudio = new Audio();
  speakAudio.autoplay = true;

  // onClick of first interaction on page before I need the sounds
  // (This is a tiny MP3 file that is silent and extremely short - retrieved from https://bigsoundbank.com and then modified)
  speakAudio.src = "data:audio/mpeg;base64,SUQzBAAAAAABEVRYWFgAAAAtAAADY29tbWVudABCaWdTb3VuZEJhbmsuY29tIC8gTGFTb25vdGhlcXVlLm9yZwBURU5DAAAAHQAAA1N3aXRjaCBQbHVzIMKpIE5DSCBTb2Z0d2FyZQBUSVQyAAAABgAAAzIyMzUAVFNTRQAAAA8AAANMYXZmNTcuODMuMTAwAAAAAAAAAAAAAAD/80DEAAAAA0gAAAAATEFNRTMuMTAwVVVVVVVVVVVVVUxBTUUzLjEwMFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQsRbAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVf/zQMSkAAADSAAAAABVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV";

  let lang = 'de-DE';
  //https://europe-west3-gitty-339716.cloudfunctions.net/texttospeech?text=Es%20gibt%20kein%20Bier%20auf%20Hawai
  const historyKey = "history4";
  var conversation = JSON.parse(localStorage.getItem(historyKey) || "[]");

  const queryString = window.location.search;
  const urlParams = new URLSearchParams(queryString);
  const API_KEY = urlParams.get('API_KEY');

  debug("loaded");
  window.addEventListener("DOMContentLoaded", () => {
    const button = document.getElementById("button");
    const result = document.getElementById("result");
    const output = document.getElementById("output");
    const main = document.getElementsByTagName("main")[0];
    let listening = false;
    let lastResult = "";
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (typeof SpeechRecognition !== "undefined") {
      const recognition = new SpeechRecognition();
      recognition.lang = lang;
      const stop = () => {
        debug("stop");
        main.classList.remove("speaking");
        debug("stopped");
      };

      const start = () => {
        debug
        main.classList.add("speaking");
        recognition.start();
        result.textContent = "";
        output.textContent = "";
        debug("started");
      };

      const onResult = event => {
        result.innerHTML = "";
        for (const res of event.results) {
          if (res.isFinal) {
            lastResult = res[0].transcript;
          }
          result.textContent = res[0].transcript;
        }
      };
      const end = event => {
        debug("end");
        completeTranscript(lastResult, recognition);
        debug("ended");
      };
      recognition.addEventListener("end", end);
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.addEventListener("result", onResult);

      button.addEventListener("touchstart", event => {
        debug("touchstart");
        speakAudio.play();
        listening ? stop() : start();
        listening = true;
      });
      button.addEventListener("touchend", event => {
        debug("touchend");
        listening ? stop() : start();
        listening = false;
      } );
    }
  });


  async function completeTranscript(transcript, recognition) {
    debug("completeTranscript");
    recognition.stop();
    let history = "";
    if (conversation.length > 0) {

      history += "Our conversation so far:\n\n"
      conversation.forEach(item => {
        history += `I said: "${item.input}"\n\n`;
        history += `You responded: "${item.output}"\n\n\n`;
      });

    } else {
      console.log("conversation is empty");
    }
    history += `I say: "${transcript}"\n\n`;
    history += `You respond:`;
    document.getElementById('output').innerHTML="<i class='fa fa-spinner fa-spin fa-4x'></i>";
    const completedText = await completeText(history);
    debug("completedText: " + completedText);
    document.getElementById('output').innerHTML="";
    document.getElementById('output').textContent = completedText;
    let turn = {
      input: transcript,
      output: completedText
    }
    conversation.push(turn);
    console.log(history);
    localStorage.setItem(historyKey, JSON.stringify(conversation));
    speakRemote(completedText);
    
  }

  function speakRemote(text) {
    speakAudio.src = "https://europe-west3-gitty-339716.cloudfunctions.net/texttospeech?text=" + encodeURIComponent(text);
  }

  function speak(text) {
    // Synthesize speech from the text
    const synth = window.speechSynthesis;
    const speakText = new SpeechSynthesisUtterance(text);
    const voices = speechSynthesis
      .getVoices()
      .filter(voice => voice.lang === lang);
    speakText.voice = voices[0];
    speakText.lang = lang;
    // if on android mobile increase the rate of speech 
    if (navigator.userAgent.toLowerCase().indexOf("android") > -1) {
      speakText.rate = 1.2;
    }
    speakText.onerror = (event) => {
      debug("An error has occurred with the speech synthesis:");
      debug(event.error);
    }
    debug("speak");
    synth.speak(speakText);
    debug("done");
  }

  async function completeText(text) {
    debug("completeText");
    
    var url = "https://api.openai.com/v1/completions";
    var bearer = 'Bearer ' + API_KEY;
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Authorization': bearer,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        "prompt": text,
        "model": "text-davinci-003",
        "max_tokens": 1024
      })


    })
      .catch(error => {
        console.log('Something bad happened ' + error)
        debug('Something bad happened ' + error);
      });
    debug("request sent");
    data = await response.json();
    debug("request received");
    return data['choices'][0].text;

  }

  function debug(text) {
    // get the debug element
    let debug = document.getElementById('debug');
    // create a new p element
    let p = document.createElement('p');
    // set the text of the p element to the text passed to the function
    p.textContent = text;
    // append the p element to the debug element
    debug.appendChild(p);
  }
  var debugflag = false;
  function toggleDebug() {
    debugflag = !debugflag;
    if (debugflag) {
      document.getElementById("debug").style.display = "block";
    } else {
      document.getElementById("debug").style.display = "none";
    }
  }

  function toggleHistory() {
    conversation = [];
    localStorage.setItem(historyKey, JSON.stringify(conversation));
  }

  const form = document.querySelector('form');

  form.addEventListener('change', event => {
    lang = event.target.value;
  });

</script>

</html>